Bootstrap: localimage
FROM: ../common/nvidia_cuda_9.0_cudnn_7_ubuntu16.04.img
%environment
    # Can't get automatic sourcing of the HPCX init file. So hardwiring it here.
    # Version specific assignments here.
    export CUDA_DIR=/usr/local/cuda
    export HPCX_DIR=/opt/hpcx-v2.0.0-gcc-MLNX_OFED_LINUX-4.2-1.0.0.0-ubuntu16.04-x86_64
    export HPCX_MPI_DIR=${HPCX_DIR}/ompi-v3.0.x
    export HPCX_IPM_DIR=${HPCX_MPI_DIR}/tests/ipm-2.0.6
#    # No version specific specifications below this line.
    export HPCX_IPM_LIB=${HPCX_IPM_DIR}/lib/libipm.so
    export HPCX_BUPC_DIR=${HPCX_DIR}/bupc
    export HPCX_IBPROF_LIB=${HPCX_DIR}/ibprof/lib/libibprof.so
    export HPCX_SHARP_DIR=${HPCX_DIR}/sharp
    export HPCX_HCOLL_DIR=${HPCX_DIR}/hcoll
    export HPCX_MXM_DIR=${HPCX_DIR}/mxm
    export HPCX_UCX_DIR=${HPCX_DIR}/ucx
    export HPCX_IBPROF_DIR=${HPCX_DIR}/ibprof
    export HPCX_FCA_DIR=${HPCX_DIR}/fca
    export HPCX_OSHMEM_DIR=${HPCX_MPI_DIR}
    export HPCX_MPI_TESTS_DIR=${HPCX_OSHMEM_DIR}/tests
    export SHMEM_HOME=${HPCX_MPI_DIR}
    export OPAL_PREFIX=${HPCX_MPI_DIR}
    export OMPI_HOME=${HPCX_MPI_DIR}
    export MPI_HOME=${HPCX_MPI_DIR}
    export OSHMEM_HOME=${HPCX_MPI_DIR}
    export LD_LIBRARY_PATH=${HPCX_DIR}/mxm/lib:${HPCX_UCX_DIR}/lib:${HPCX_SHARP_DIR}/lib:${HPCX_HCOLL_DIR}/lib:${HPCX_MPI_DIR}/lib
    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${CUDA_DIR}/lib64:${CUDA_DIR}/extras/CUPTI/lib64
    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/.singularity.d/libs:/usr/lib/x86_64-linux-gnu
    export PATH=${HPCX_DIR}/bupc/bin:${HPCX_DIR}/hcoll/bin:${HPCX_DIR}/ucx/bin:${HPCX_DIR}/mxm/bin
    export PATH=${PATH}:${HPCX_MPI_DIR}/bin:${CUDA_DIR}/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin
    export CPATH=${HPCX_MPI_DIR}/include:${HPCX_UCX_DIR}/include:${HPCX_SHARP_DIR}/include:${HPCX_MXM_DIR}/include:${HPCX_HCOLL_DIR}/include
    export JUPYTER_CONFIG_DIR=/.jupyter

%labels
	Maintainer Stephen Fleischman
    Framework TensorFlow
    Version  1.8
    Build  CUDA 9.0 cuDNN 7.0 x86_64 AVX2 (Broadwell), OFED IB.
    Installed Horovod, OpenNMT, NVidia examples

%help
    TensorFlow 1.8 GPU Singularity Container
    Maintainer: Stephen Fleischman

%files
    # To get the driver from teh Mellanox website requires accepting the EULA. I suppose you could send a post with curl or wget but I'm not going to bother figuring out how.
    # Anyway in my lab the downloads are slow and will often time out so it is easier and much faster, especially in a development phase, to download locally and copy in here.
    # Update when versions change
    ../common/MLNX_OFED_LINUX-4.2-1.2.0.0-ubuntu16.04-x86_64.tgz
    ../common/hpcx-v2.0.0-gcc-MLNX_OFED_LINUX-4.2-1.0.0.0-ubuntu16.04-x86_64.tbz
    nv-tensorrt-repo-ubuntu1604-cuda9.0-rc-trt4.0.0.3-20180329_1-1_amd64.deb
    ../common/jupyter_notebook_config.py
    nvidia-examples.tgz

%post
    # Update when versions change
    export OFED=MLNX_OFED_LINUX-4.2-1.2.0.0-ubuntu16.04-x86_64
    export HPCX=hpcx-v2.0.0-gcc-MLNX_OFED_LINUX-4.2-1.0.0.0-ubuntu16.04-x86_64
    export TRT=nv-tensorrt-repo-ubuntu1604-cuda9.0-rc-trt4.0.0.3-20180329_1-1_amd64
    export HPCX_MPI_DIR=/opt/${HPCX}/ompi-v3.0.x

    ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 
    export LD_LIBRARY_PATH=/host-libs:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs
    export PATH=/usr/local/cuda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin


    # Set up our notebook config.
    mkdir -p /.jupyter && mv /jupyter_notebook_config.py /.jupyter && chmod 777 /.jupyter && echo $(ls /.jupyter)
    
    # tensorrt
    dpkg -i /${TRT}.deb && rm -f /${TRT}.deb
    apt-get update && apt-get install -y --no-install-recommends \
        build-essential \
        curl \
        git \
        net-tools \
        lsof \
        vim \
        libcurl3-dev \
        libfreetype6-dev \
        libpng12-dev \
        libzmq3-dev \
        libibverbs-dev \
        pkg-config \
        python3 \
        python3-dev \
        python3-venv \
        python3-pip \
        python3-setuptools \
        python3-wheel \
        rsync \
        software-properties-common \
        unzip \
        zip \
        zlib1g-dev \
        openjdk-8-jdk \
        openjdk-8-jre-headless \
        wget \
        tar \
        bzip2 \
        environment-modules \
        libhwloc-dev \
        hwloc \
        libhwloc-common \
        libhwloc-plugins \
        iputils-ping \
        openssh-server\
        pylint \
        tensorrt \
        python3-libnvinfer-doc \
        uff-converter-tf
    apt-get clean && rm -rf /var/lib/apt/lists/*
    ln -sf /usr/bin/python3 /usr/bin/python
    ln -sf /usr/bin/pip3 /usr/bin/pip
    pip3 --no-cache-dir install \
        jupyter \
        matplotlib \
        numpy \
        scipy \
        sklearn \
        graphviz \
        pandas \
        future \
        absl-py && \
     pip3 --no-cache-dir install \
        flask \
        redis \
        Pillow

     pip3 --no-cache-dir install pycuda

     # Install Mellanox OFED drivers and HPCX SKD
     tar xvzf /${OFED}.tgz && rm /${OFED}.tgz
     cd $OFED &&  yes|./mlnxofedinstall --without-fw-update && cd .. &&  rm -rf $OFED
     cd /opt &&  tar xjf /${HPCX}.tbz && rm -f /${HPCX}.tbz

     # Set up Bazel.
     # Running bazel inside a `docker build` command causes trouble, cf: https://github.com/bazelbuild/bazel/issues/134
     # The easiest solution is to set up a bazelrc file forcing --batch.
     # echo "startup --batch" >>/etc/bazel.bazelrc

     # Similarly, we need to workaround sandboxing issues:
     # https://github.com/bazelbuild/bazel/issues/418
     echo "build --spawn_strategy=standalone --genrule_strategy=standalone" >> /etc/bazel.bazelrc

     export BAZEL_VERSION=0.10.0
     mkdir -p /bazel
     cd /bazel
     curl -H "User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36" -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh
     curl -H "User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36" -fSsL -o /bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE
     chmod +x bazel-*.sh
     ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh
     cd / && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh

    # Download and build TensorFlow.
    cd /
    git clone https://github.com/tensorflow/tensorflow.git tensorflow
    cd tensorflow
    git reset --hard 93bc2e2072e0daccbcff7a90d397b704a9e8f778
    git submodule update

    # Configure the build for our CUDA configuration.
    export CI_BUILD_PYTHON=/usr/bin/python3 
    export PYTHON_BIN_PATH=/usr/bin/python3 
    export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH 
    export TF_NEED_CUDA=1 
    export TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.5,3.7,5.2,6.0,6.1,7.0 
    export TF_CUDA_VERSION=9.1 
    export TF_CUDNN_VERSION=7.1.2 
    export TF_ENABLE_XLA=1 
    export TF_NEED_TENSORRT=1 
    export TF_NEED_VERBS=1 
    export TF_NEED_JEMALLOC=1 
    LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs:${LD_LIBRARY_PATH} \
        tensorflow/tools/ci_build/builds/configured GPU \
        bazel build -c opt --copt=-march="broadwell" --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" \
                   --copt="-O3" --copt=-mavx --copt=-mavx2 \
                   tensorflow/tools/pip_package:build_pip_package 
    rm /usr/local/cuda/lib64/stubs/libcuda.so.1 
    export CI_BUILD_PYTHON=/usr/bin/python3 
    export PYTHON_BIN_PATH=/usr/bin/python3 
    export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH 
    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip 
    pip3 --no-cache-dir install --upgrade /tmp/pip/tensorflow-*.whl 
    rm -rf /tmp/pip /root/.cache

    # Uber Horvod
    mkdir -p /scrap/jenkins/workspace/hpc-power-pack/label/r-vmb-ubuntu16-u4-x86-64-MOFED-CHECKER
    ln -sf  /opt /scrap/jenkins/workspace/hpc-power-pack/label/r-vmb-ubuntu16-u4-x86-64-MOFED-CHECKER/hpcx_root
    ln -sf /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1

    export PATH=$HPCX_MPI_DIR/bin:$PATH
    export OLD_LD_LIBRARY_PATH=$LD_LIBRARY_PATH
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64/stubs
    export HOROVOD_NCCL_INCLUDE=/usr/include/nccl.h
    export HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu
    HOROVOD_GPU_ALLREDUCE=NCCL pip install horovod
    rm  /scrap/jenkins/workspace/hpc-power-pack/label/r-vmb-ubuntu16-u4-x86-64-MOFED-CHECKER/hpcx_root
    rm -rf /scrap/jenkins/workspace/hpc-power-pack/label/r-vmb-ubuntu16-u4-x86-64-MOFED-CHECKER
    rm /usr/local/cuda/lib64/stubs/libcuda.so.1
    export LD_LIBRARY_PATH=OLD_LD_LIBRARY_PATH

    # Install OpenNMT-tf for machine translation
    git clone --depth 1 --branch r1 --single-branch https://github.com/OpenNMT/OpenNMT-tf.git && \
    cd / && pip3 install OpenNMT-tf
    #Install NVidia Examples from the nvcr.io/tensorflow:18.04-py3 NGC image
    cd / && tar xvzf /nvidia-examples.tgz && rm /nvidia-examples.tgz

    ldconfig -v

%runscript
    echo "Singularity Container: TensorFlow 1.8, Ubuntu 16.04, CUDA 9.0, cuDNN 7, python 3.5, AVX2 instructions."
    echo "The image contains: Jupyter, tensorrt 4.0RC, horovod, OpenNMT for TensorFlow"
